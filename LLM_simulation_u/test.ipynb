{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd1a581-2aad-43c0-8770-7bbdbbfdc50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uav/anaconda3/envs/thor/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-07-18 14:20:19.417957: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-18 14:20:19.442144: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 14:20:19.871567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext cudf.pandas\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from agent2 import Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c70513e-8a96-4c1d-8cbc-2579a8cb178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analytics_data = pd.read_csv(\"/home/uav/Documents/AI_Hunter/LLMS/ulg_data/wind1_context.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1fbb32-bab8-4df0-9da9-a56cfdeffb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mode\\n description:- uint8 ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analytics_data[Analytics_data[\"parameter\"]==\"mode\"][\"content\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3db0f-51a8-4609-84f9-3ddcc7fbf0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analytics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2a9d8-6abb-43da-b8c9-2247f4376cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analytics_data = pd.read_csv(\"/home/uav/Documents/AI_Hunter/LLMS/LLM_simulation_u/Analytics_knowledge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa257ce-d2bc-4a41-813a-349715569f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analytics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6903ec-d509-432b-ba95-921f0daf0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Agents.load_images_from_folder(\"i want scenarios that involve very high wind conditions. i wan to test my system more in the context of wind so make sure i cover all edge cases in that conext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d1897-6451-4e46-add8-9e5f21c71699",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdc9a8-f210-4ad3-a762-2f0af4ae811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text,iamges = Agents.Analytics_two(\"i want scenarios that involve very high wind conditions. i wan to test my system more in the context of wind so make sure i cover all edge cases in that conext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d953d35-8a7b-45ee-91e9-2c135acae42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iamges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7a0e8-f701-4a98-a235-ea96ca49ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd88da-2b44-4076-b319-2744e4966539",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = iamges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0382b493-0631-430c-8a1e-737df107239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Agents.load_images_from_folder(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af55a-8f00-465e-b2d1-3d1bf7a8e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\" \n",
    "        # quantization_config = BitsAndBytesConfig(load_in_4bit=True)#,llm_int4_threshold=6.0,llm_int8_skip_modules=None,trust_remote_code=True)\n",
    "        \n",
    "model, tokenizer, processor = Agents.model_manager.load_model(model_id, device_map=\"cuda\", quantization_config = nf4_config)\n",
    "\n",
    "responses_ll = []\n",
    "for i in range(0,len(images),5):\n",
    "    image_tags = \"\".join([f\"<|image_{j+1}|>\" for j in range(len(images[i:i+5]))])\n",
    "\n",
    "    promt_a = \"\"\"\n",
    "    Analytics Report Request for Drone ULG Data\n",
    "    I have a set of plots derived from my drone's ULG data. As an expert in drone analytics, I would like you to analyze these plots and provide a detailed report.\n",
    "    The report should include the following:\n",
    "    1)Understanding the Plots 2)Impact on Drone Behavior 3)Key Observations 4)Correlations Between Plots\n",
    "    Rules:\n",
    "    1)Understand the plots and provide your expert opinion.\n",
    "    2)Keep the response crisp and summarized, with key observations highlighted.\n",
    "    3)Highlight any correlations between plots.\n",
    "    Please ensure the report is comprehensive yet concise, offering actionable insights and a clear understanding of the drone's performance based on the ULG data.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [ \n",
    "        {\"role\": \"user\", \"content\":f\"{image_tags}i would like a detailed analysis of the images I have provided, focusing on the metrics displayed and their impact on drone behavior\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"understand what is present in images and give very insightfull responses as per user questions\"}, \n",
    "        {\"role\": \"user\", \"content\": f\"{promt_a}\"} \n",
    "    ] \n",
    "\n",
    "    # image = Image.open(requests.get(url, stream=True).raw) \n",
    "\n",
    "    batch_images = images[i:i+5]\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    for j, image in enumerate(batch_images):\n",
    "        image.id = j + 1\n",
    "    inputs = processor(prompt,batch_images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 1000, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "    responses_ll.append(response)\n",
    "Analysis = \"\"\n",
    "for res in responses_ll:\n",
    "    Analysis += res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41b72b-ac03-4073-9ee5-cbce6948dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686b3ea-8977-4057-96a5-bb3a826ee529",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_query = input(\"Enter your question or type 'exit' to finish: \")\n",
    "    if user_query.lower() == 'exit':\n",
    "        break\n",
    "    prompt_Ab = f\"\"\"\n",
    "    understand the Analytics report completely like An Domain Expert and answer the user Question\n",
    "    ==========================\n",
    "    Analysis data:-{Analysis}\n",
    "    ==========================\n",
    "    instructions:-\n",
    "    user questions :-{user_query}\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"intelligent AI system cabale of Answering any question you have\"},  # Passing previous responses as memory\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt_Ab}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)\n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]  # Remove input tokens\n",
    "    response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    print(\"AI Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8164344-508d-48c0-b13d-b4ab333c7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent2 import search_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a90a34-876a-4511-bbba-66bec0a05329",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_query = input(\"Enter your question or type 'exit' to finish: \")\n",
    "    if user_query.lower() == 'exit':\n",
    "        break\n",
    "    cosine_similarity, indices = search_a(user_query, 10)\n",
    "    contextlist = Analytics_data.iloc[indices[0]][\"parameter\"]\n",
    "    # context = combine_context(contextlist)\n",
    "    Agents.create_and_save_plots(df,contextlist.to_list(),user_query)\n",
    "    \n",
    "    image_tags = \"\".join([f\"<|image_{j+1}|>\" for j in range(len(contextlist.to_list()))])\n",
    "    path_to_load = input(\"give the path to directory\")\n",
    "    images_n = Agents.load_images_from_folder(path_to_load)\n",
    "    promt_a = \"\"\"\n",
    "    Analytics Report Request for Drone ULG Data\n",
    "    I have a set of plots derived from my drone's ULG data. As an expert in drone analytics, I would like you to analyze these plots and provide a detailed report.\n",
    "    The report should include the following:\n",
    "    1)Understanding the Plots 2)Impact on Drone Behavior 3)Key Observations 4)Correlations Between Plots\n",
    "    Rules:\n",
    "    1)Understand the plots and provide your expert opinion.\n",
    "    2)Keep the response crisp and summarized, with key observations highlighted.\n",
    "    3)Highlight any correlations between plots.\n",
    "    Please ensure the report is comprehensive yet concise, offering actionable insights and a clear understanding of the drone's performance based on the ULG data.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [ \n",
    "        {\"role\": \"user\", \"content\":f\"{image_tags}\\ni would like a detailed analysis of the images I have provided, focusing on the metrics displayed and their impact on drone behavior\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"understand what is present in images and give very insightfull responses as per user questions\"}, \n",
    "        {\"role\": \"user\", \"content\": f\"{promt_a}\"} \n",
    "    ] \n",
    "\n",
    "    # messages = [\n",
    "    #     {\"role\": \"system\", \"content\": f\"{Analysis}\"},  # Passing previous responses as memory\n",
    "    #     {\"role\": \"user\", \"content\": f\"{user_query}\"}\n",
    "    # ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(prompt,images_n, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)\n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]  # Remove input tokens\n",
    "    response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    print(\"AI Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96553352-1f63-4f55-abf3-5783c594f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/uav/Documents/AI_Hunter/LLMS/total_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e3b75-55e3-4481-9a3e-6eb976882114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a41ff8-88df-445a-96af-a9bf25ea862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"filename\"]==\"wikipedia\"][\"synopsis\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbc68c-a392-425b-b247-eae09dea2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(query):\n",
    "    embed_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    embeddings = embed_model.encode(query)\n",
    "    torch_embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    norm_embeddings  = F.normalize(torch_embeddings, p=2.0, dim=-1)\n",
    "    return norm_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238971a2-c5d6-45aa-8c55-88bf69d5b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d579c67-1691-48b6-8d3a-c6f4f58040d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = get_embeddings(df[\"content\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bde749-a7e0-407b-8a7b-c6e7eb454646",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cbed87-7bab-4219-bcdc-56337ac99ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([d,df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5fd64b-2814-495f-b817-187071ae7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"/home/uav/Documents/AI_Hunter/LLMS/ulg_data/wind1_context.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b8bba-8937-4ecd-981e-7da6ccaa5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241a4cf-13ff-4f1b-95f5-f18cf353eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent2 import Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade12dd5-24db-4c0d-82dd-b8922c735626",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Agents.Analytics_one(\"i want scenarios that involve very high wind conditions. i wan to test my system more in the context of wind so make sure i cover all edge cases in that conext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70276cc8-bec4-4d1e-8315-7ae257c0b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2162f-c6ab-40b4-a6ec-a5ef3595a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/uav/Documents/AI_Hunter/LLMS/ulg_data/wind1_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fea14-65ec-4f45-ac7c-f914e94915a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7543b-ec5d-44ad-9b09-07e598187c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_columns = [col for col in df.columns if df[col].notnull().any()]\n",
    "responses = []\n",
    "columns_l = []\n",
    "for i in range(0,len(non_empty_columns),250):\n",
    "    #{Analytics_list[0][1]}\n",
    "    prompt_t= f\"\"\"\n",
    "    here are analytics i need for my root cause Analytics and\n",
    "    \"Analytics Topics\"  = {text}\n",
    "    ===============================\n",
    "    \"ulg_data columns\":-{non_empty_columns[i:i+250]}\n",
    "    and here are ulg data columns of my drone now tell me all what are columns required for above metrics\n",
    "    \n",
    "    rules:\n",
    "    1)I have Given you \"Analytics Topics\" i need you to look contextually relevent \"ulg_data columns\" so that i can make better analytics of this data\n",
    "    2)Select only the columns that will enhance the quality and accuracy of the analytics.\n",
    "    3)Ensure the selection is comprehensive but not redundant.\n",
    "    4) just give column names no need for description and column names as same as given input\n",
    "    \"\"\"\n",
    "    # print(prompt_t)\n",
    "    messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"I am an sUAS Software designer and I need your assistance on Automating UAV testing\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"I am an AI system capable of answering any query you have\"}, \n",
    "    {\"role\": \"user\", \"content\": prompt_t} ]\n",
    "\n",
    "    temp = 0.0\n",
    "    sample = False\n",
    "    tokens = 1000\n",
    "    agent_response = Agents.model_x(messages, temp, sample,tokens,\"microsoft/Phi-3-medium-128k-instruct\")\n",
    "    responses.append(agent_response[-1][\"content\"])\n",
    "    torch.cuda.empty_cache()\n",
    "    # return agent_response[-1][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef838d-803a-4e1e-b742-91230296a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[1].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825eea3-413b-41e9-acf2-7c5a00ce4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(responses)):\n",
    "    pattern = r'-\\s*(\\S+)'\n",
    "    extracted_values = re.findall(pattern, responses[i])\n",
    "    columns_l.append(extracted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a370e-8ee6-4593-b498-6c5ba64da726",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03333770-7e65-4872-b42c-d2f00f6fe36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_l = [[item.strip(\"'\") for item in sublist] for sublist in columns_l]#cleaning strings\n",
    "flattened_data = [item for sublist in columns_l for item in sublist]#flatten the list\n",
    "filtered_data = [item for item in flattened_data if item in non_empty_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0d301-a8c6-40ae-9424-e7c95a7d35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agents.create_and_save_plots(df,filtered_data,\"i want scenarios that involve very high wind conditions. i wan to test my system more in the context of wind so make sure i cover all edge cases in that conext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf448b-36eb-42c6-8bf6-d60c7aed3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_r = [item for item in flattened_data if item+\"[0]\"  in non_empty_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cf32f-9643-4335-86f0-4b43f91ee21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flattened_data:\n",
    "    if i+\"[0]\" in non_empty_columns:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c5119-f0ef-48cc-a4d3-f1e98f68bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14152ba5-addb-42c3-a65a-ca99186a4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_data),len(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb27533-031e-4832-9d07-a73b76f43a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv(\"/home/uav/Documents/AI_Hunter/LLMS/ulg_data/wind1_filtered.csv\")\n",
    "# df2 = pd.read_csv(\"sub_para.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207b1d1-f865-4e70-8681-f2a2b0ebe8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"content\"] = df2[\"parameter\"] +\"\\n description:- \"+df2[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1812e-e3ed-4594-8af8-bc46403d7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a5ba5-3a2f-46ed-a45b-8bb664f8d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2 = df2[df2['parameter'].isin(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6e103-deb9-4c1f-9079-46f6e6f22b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df2 = normalized_df2.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7871edf-68fb-4ad4-a2e2-31dd5497431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in normalized_df2[\"parameter\"].to_list():\n",
    "    if i not in df1.columns.to_list():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c74a0a-347a-4f2b-9f8f-b2680e6e2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df2.to_csv(\"wind1_context.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20576c-92fc-4df9-a2c2-e2ee171d5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalized_df2[\"parameter\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e606291-ca89-4103-8c1f-f9b491820bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "l = []\n",
    "for i in df1.columns.to_list():\n",
    "    if i not in normalized_df2[\"parameter\"].to_list():\n",
    "        l.append(i)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59bf70-a30f-417f-a72b-32b79fc7d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df2.dropna(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa41f1-e1cd-4331-9ed8-a3247970df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0b457-33f2-44e5-a13c-24d2cc1c9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(normalized_df2)):\n",
    "    if normalized_df2[\"parameter\"][i] in ll:\n",
    "        normalized_df2[\"parameter\"][i] = normalized_df2[\"parameter\"][i]+\"[0]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35932c5e-58e5-4c7e-85e9-5340e3411fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in normalized_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead5de9-7ebb-496c-8d37-b38149e5ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ced2ad-a132-4992-91b7-1e97066271e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = []\n",
    "for i in normalized_df2[\"parameter\"].to_list():\n",
    "    if i not in df1.columns.to_list():\n",
    "        ll.append(i)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f6e7a-23ff-4ee8-837a-af546b148371",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465ca56-1634-4a87-ac6c-d49a878bf899",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2[\"parameter\"].to_list() == df1.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e102372-db79-4ed4-8af2-3291d5712bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ac644-3eea-40e5-8be5-4f033b867c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_t = df1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0770c45-f661-45f2-8a4c-833d282837d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_m = df1_t.loc[l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66dccf-01f1-46f8-9852-5de9a58337f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df1_m.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf66f67-8f38-4e66-8e96-90fed8e81fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"/home/uav/Documents/AI_Hunter/LLMS/ulg_data/wind1_filtered.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6363a-8c5d-4e64-94dc-958b8ee7fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b3cfd-8668-4eea-86d8-df7e917da903",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1_columns = df1.columns\n",
    "filtered_df2 = df2[df2['parameter'].isin(csv1_columns)]\n",
    "normalized_df2 = df2[df2['parameter'].isin(normalized_csv1_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87927ee-e870-4a9f-bf64-847106fef3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in normalized_df2[\"parameter\"].to_list():\n",
    "    if i not in filtered_df2[\"parameter\"].to_list():\n",
    "        l.append(i)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74a8cb-b220-4eca-9d2e-3cdb19ec87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3cf3d-e9c9-4550-ae6c-076d02bce1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = l + filtered_df2[\"parameter\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea965caa-5a01-4822-b2e3-4cac89f4a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8d21a-2318-4841-97b6-f41afbeede81",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd5338-d5d6-4569-9008-089e1a2f2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalized_csv1_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45adab-c0d9-4c52-8202-4710967023ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "l  = [] \n",
    "for i in normalized_csv1_columns:\n",
    "    if i not in filtered_df2[\"parameter\"].to_list():\n",
    "        l.append(i+\"[0]\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b292f-3716-4a3a-a19c-b1d8d5b3ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d831aa-02c4-4334-ab8c-8a5383f5bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalized_csv1_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a4a35-3219-46d0-9464-7c66d274849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv1_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74b78e-cccf-4c2e-8c2d-ea9eb4a2adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_column_name(column_name):\n",
    "    return re.sub(r'\\[.*\\]', '', column_name)\n",
    "\n",
    "normalized_csv1_columns = set(normalize_column_name(col) for col in df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebf830-7651-485d-bae8-e58af55180fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in normalized_csv1_columns:\n",
    "    if i not in filtered_df2[\"parameter\"].to_list():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9663b-7eac-49c0-895c-1be7e0f07d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2[\"parameter\"] == \"accel_bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a61de8-b24e-4f9b-8595-9a73b5ba856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1_columns = df1.columns\n",
    "filtered_df2 = df2[df2['parameter'].isin(csv1_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa94b93-da8d-460b-b569-0239333bd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2[\"parameter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc9a35-c4f9-4092-8146-17637e6d98e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_t = df1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa87b3-e965-4e3d-a125-eefb14583186",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2[\"parameter\"].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e7991-09da-46ae-a2aa-2aa80646ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = df1.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22bc544-e0a3-4ab8-af7f-da590c40e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_t.iloc(\"target_component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a3062-11fd-4b42-85d6-5edc87266243",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rows = df1_t.loc[filtered_df2[\"parameter\"].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c776a-b5ed-43d4-a8bb-07f3a210d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0cd98-722e-45a5-9f21-e81fe4bc75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = df1[csv1_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01322ee9-ccd6-4bab-b426-105a0f260c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in normalized_csv1_columns:\n",
    "    if i not in csv1_columns:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e578cd7-cd24-4bfa-8930-c83bd77a8ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141b221-8b8e-4fac-9a8a-074633bb25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in df1.columns.to_list():\n",
    "    if i in df2[\"parameter\"].to_list():\n",
    "        l.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874838e0-7491-436d-9464-f737ea802c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0691a-d04c-4aeb-a401-473a692ab181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e8ef9-3cb4-425a-81f6-9363ca31ce16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6ec4f-4571-4e73-8142-caebc39a795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "model_id = \"microsoft/Phi-3-medium-128k-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    quantization_config=nf4_config,\n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26edef-d7fb-44c2-8ee7-60abb8e96923",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"i want scenarios that involve very high wind conditions. i wan to test my system more in the context of wind so make sure i cover all edge cases in that conext\"\n",
    "mission_data = pd.read_csv(f\"user_questions/{user_input}_1.csv\")\n",
    "# df1 = pd.read_csv(\"/home/uav/Documents/AI_Hunter/LLMS/LLM_simulation/Test the flight stability of my sUAS during river search and rescue operation_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1311e-3f8d-402d-8d91-78cff908322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "def extract_scenarios(text):\n",
    "    pattern = r'(Scenario \\d+:\\n\\n[\\s\\S]*?)(?=Scenario \\d+:|$)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    scenarios = [match.strip() for match in matches]\n",
    "    return scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39e090-d261-4d71-9e1f-106e2e4e6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = extract_scenarios(mission_data[\"Senarios\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9db4e7-856d-41ae-b0aa-2d1a250875b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[1].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2956d9d-8d53-4d3d-a88f-275b16901e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"environment\"][0].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb6fb8-03b2-4d01-ab3b-352b1a5455de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Senarios\"][0].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01cc86f-d118-43ba-98f9-d0e03343fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent2 import Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652d512-5404-45e5-a8d0-00f77972cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Agents.Analytics_one(\"i want scenarios that involve very high wind conditions. i wan to test my system more in the context of wind so make sure i cover all edge cases in that conext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247b477-14ef-4432-b9e1-c3b2702368fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f85a3-caef-46dc-8553-27724c6ed90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i want to test wind profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebd4c9-74b9-45c9-8eeb-62bcd7a1034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sub_para.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495bc2c5-1b16-488b-9f4f-d1cfa0858d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b39a1-3dd6-46e0-8f68-5b1cd926d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\".join(data[\"parameter\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492738a-ecb0-480d-ab0d-d26f577a8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec70c0-f43b-4f53-bb3b-5e2c6b90904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "torch.cuda.empty_cache()\n",
    "Analytics_list = []\n",
    "# pattern = 'Scenario 1(\\d+):\\n([\\s\\S]*?)\\n\\n'\n",
    "pattern = r'(Scenario \\d+: [\\s\\S]*?)(?=Scenario \\d+:|$)'\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "for match in matches:\n",
    "    Analytics_list.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778128f-2270-430a-a531-045e4b8aa862",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analytics_list[0].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a23a8d-4c85-4484-b18a-799bd3601248",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01554121-accd-41bd-afa3-0535895709f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall(pattern, text, re.DOTALL)\n",
    "scenarios = {f'Scenario {match[0]}': match[1].strip() for match in matches}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d77f6e-9478-48c1-84dc-924da34a821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6c093-c078-464f-9dd7-1e4f91289c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf2cb9-03a8-4b02-ac90-f806d03badc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b1d7e-1bc8-48c5-a002-d7b37c2515de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import faiss\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from transformers import BitsAndBytesConfig\n",
    "from agent import Agents#,search_a\n",
    "from transformers import AutoModelForCausalLM ,AutoTokenizer,AutoProcessor,pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff3194-4686-4e8d-b93d-5aa65a0084b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"i want test wind profile of system so that i cover all edge cases in the context\"\n",
    "scenario_response,cotext = Agents.scenario_generator_Agent(user_input)\n",
    "torch.cuda.empty_cache()\n",
    "missions, rest = Agents.helper_for_mission_and_environment(scenario_response)\n",
    "\n",
    "mission_responses = []\n",
    "environment_responses = []\n",
    "\n",
    "# for mission in missions:\n",
    "    # mission_response = Agents.Mission_Agent(mission,mission_type)\n",
    "    # mission_responses.append(mission_response)\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "# for rest_part in rest:\n",
    "#     environment_response = Agents.Environment_specification_Agent(rest_part)\n",
    "#     environment_responses.append(environment_response)\n",
    "#     torch.cuda.empty_cache()\n",
    "# environment_json_list, mission_json_list,index = Agents.json_extraction(environment_responses, mission_responses)\n",
    "# try:\n",
    "#     df1 = pd.DataFrame([user_input,cotext,scenario_response,str(index)])\n",
    "#     df1 = df1.T\n",
    "#     df1.columns = [\"question\",\"context\",\"Senarios\",\"index\"]\n",
    "#     df2 = pd.DataFrame([mission_json_list,environment_json_list])\n",
    "#     df2 = df2.T\n",
    "#     df2.columns =[\"misson\",\"environment\"]\n",
    "#     df1.to_csv(f\"{user_input}_1.csv\",index=False)\n",
    "#     df2.to_csv(f\"{user_input}_2.csv\",index=False)\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19ff94-3fc0-4cff-8263-7993cb0cdb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ee91b-728a-4cb9-a275-fbf52470ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_response = Agents.Mission_Agent(missions[0],\"px4\")\n",
    "mission_responses.append(mission_response)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d215ef-7524-48d1-b6a8-4778ebd2294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065661ef-cbe5-41b6-9b01-2c98d02fba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_response = Agents.Environment_specification_Agent(rest[0])\n",
    "environment_responses.append(environment_response)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc0d11-1e17-4c1e-a8b2-5dd132931952",
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_responses[0].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b41e0-ef37-4bad-bfae-b89fa7622235",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d5452-222b-41b9-80df-cc5c3907c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_json_list, mission_json_list,index = Agents.json_extraction(environment_responses, mission_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a8698-76e2-4ae4-9c77-448e26f4fbdd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def search_a(query,k):\n",
    "    query_embeddings = get_embeddings(query)\n",
    "    print(query_embeddings.shape)\n",
    "    query_embeddings = query_embeddings.unsqueeze(0)\n",
    "    cos_sim,cos_indices = index_a.search(query_embeddings.numpy(),k)\n",
    "    return cos_sim,cos_indices\n",
    "def get_embeddings(query):\n",
    "    embed_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    embeddings = embed_model.encode(query)\n",
    "    torch_embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    norm_embeddings  = F.normalize(torch_embeddings, p=2.0, dim=-1)\n",
    "    \n",
    "    return norm_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed15d2-be67-42ef-a043-acb708dfb049",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Analytics_data = pd.read_csv(\"Analytics_knowledge.csv\")\n",
    "\n",
    "knowledge_a = Analytics_data.drop([\"columns\",\"Unnamed: 0\"],axis=1)\n",
    "knowledge_tensor_a = torch.tensor(knowledge_a.values, dtype=torch.float32)\n",
    "normalized_embeddings_a  = F.normalize(knowledge_tensor_a, p=2.0, dim=1)\n",
    "dimension_a = knowledge_tensor_a.shape[1]\n",
    "print(dimension_a)\n",
    "res_a = faiss.StandardGpuResources()\n",
    "index_a = faiss.GpuIndexFlatIP(res_a,dimension_a)\n",
    "index_a.add(normalized_embeddings_a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646abf88-410d-48c4-8b85-b43bbb3051f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578592cd-fddd-41d7-be7a-ddeea44cdb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = input(\"Enter your question or type 'exit' to finish: \")\n",
    "\n",
    "cosine_similarity, indices = search_a(user_query, 5)\n",
    "contextlist = Analytics_data.iloc[indices[0]][\"columns\"]\n",
    "context = combine_context(contextlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbae87-cb59-4133-8779-53fc869d3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextlist,cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ba101-532d-43aa-bfef-815d4227f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contextlist.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f36b90-cc62-40e0-8708-e9c415d0a7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbaa769-f053-4d7b-8511-366232fe9781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee8a6b-4e64-44e9-aa5f-1efadd60e9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9766710f-426b-4837-afe4-b5ba752e0241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321fc5b-9c34-4ba5-a7e4-516f11755fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072883aa-55af-40eb-a4e4-4f1ecc8207e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207cce7-818a-48b3-85a7-9668f72fae07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665e8cb-5176-4d4e-98b6-e482d659c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_empty_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bd858-a9c7-456a-989f-7cb3c9d3cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = embed_model.encode(non_empty_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2f327-90de-4eb1-80f7-0f6c9e9867a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ea80d-4aaf-4a02-a9b2-5588917b005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "images = Agents.load_images_from_folder(\"/home/uav/Documents/AI_Hunter/LLMS/LLM_simulation/plots_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe2106-3d39-4a93-b2cc-326321543bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images = images[i+1:i+6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf2fe2-53b5-449d-85cf-77c0a0961ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)#,llm_int4_threshold=6.0,llm_int8_skip_modules=None,trust_remote_code=True)\n",
    "        \n",
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\" \n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", quantization_config=quantization_config,trust_remote_code=True)\n",
    "\n",
    "# cls.model =  AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", trust_remote_code=True, torch_dtype=\"auto\", _attn_implementation='flash_attention_2') # use _attn_implementation='eager' to disable flash attention\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True) \n",
    "\n",
    "images = Agents.load_images_from_folder(\"/home/uav/Documents/AI_Hunter/LLMS/LLM_simulation/plots_data\")\n",
    "\n",
    "responses_ll = []\n",
    "for i in range(0,len(images),5):\n",
    " \n",
    "    promt_a = \"\"\"based on these images give me detailed Analytics Report so that i get better understanding on my drone mission\n",
    "    and also explain in the context of drone what are these metrics \n",
    "    \"\"\"\n",
    "\n",
    "    messages = [ \n",
    "        {\"role\": \"user\", \"content\": \"<|image_1><|image_2|><|image_3|><|image_4|><|image_5|>\\nWhat is shown in this image?\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"The chart displays the percentage of respondents who agree with various statements about their preparedness for meetings. It shows five categories: 'Having clear and pre-defined goals for meetings', 'Knowing where to find the information I need for a meeting', 'Understanding my exact role and responsibilities when I'm invited', 'Having tools to manage admin tasks like note-taking or summarization', and 'Having more focus time to sufficiently prepare for meetings'. Each category has an associated bar indicating the level of agreement, measured on a scale from 0% to 100%.\"}, \n",
    "        {\"role\": \"user\", \"content\": f\"{promt_a}\"} \n",
    "    ] \n",
    "\n",
    "    # image = Image.open(requests.get(url, stream=True).raw) \n",
    "    \n",
    "    batch_images = images[i+1:i+6]\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    for j, image in enumerate(batch_images):\n",
    "        image.id = j + 1\n",
    "    inputs = processor(prompt,batch_images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 500, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "    responses_ll.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5840a-889f-4a26-9bf9-fa8b2c471be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50fe1a-0f6a-4235-bdba-53a8d03eb72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True) \n",
    "\n",
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", quantization_config=quantization_config, trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "images = Agents.load_images_from_folder(\"/home/uav/Documents/AI_Hunter/LLMS/LLM_simulation/plots_data\")\n",
    "responses_ll = []\n",
    "\n",
    "for i in range(0, len(images), 5):\n",
    "    promt_a = \"\"\"Based on these images, give me a detailed Analytics Report so that I get a better understanding of my drone mission\n",
    "    and also explain in the context of the drone what these metrics are.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create messages with the correct image tags\n",
    "    image_tags = \"\".join([f\"<|image_{j+1}|>\" for j in range(len(images[i:i+5]))])\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"{image_tags}\\nWhat is shown in these images?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The chart displays the percentage of respondents who agree with various statements about their preparedness for meetings. It shows five categories: 'Having clear and pre-defined goals for meetings', 'Knowing where to find the information I need for a meeting', 'Understanding my exact role and responsibilities when I'm invited', 'Having tools to manage admin tasks like note-taking or summarization', and 'Having more focus time to sufficiently prepare for meetings'. Each category has an associated bar indicating the level of agreement, measured on a scale from 0% to 100%.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{promt_a}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    batch_images = images[i:i+5]\n",
    "    \n",
    "    # Process the images and prompt\n",
    "    inputs = processor(prompt, batch_images, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": 500,\n",
    "        \"temperature\": 0.0,\n",
    "        \"do_sample\": False,\n",
    "    }\n",
    "\n",
    "    generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)\n",
    "\n",
    "    # Remove input tokens\n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    responses_ll.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436617fa-4a5e-4801-8b54-70bdf2bfb282",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e702d4-4c4c-4b07-8ee6-16d23ca16e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,30,5):\n",
    "    s = \"\"\n",
    "    for j in range(i,i+5):\n",
    "        s+= f\"<|image_{j+1}|>\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b7df2-f51b-457d-879e-2edbd2c7991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f586c0-cad1-4d92-94c0-c0da56de39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77f588-bfe9-4870-9a4b-d7d3734d5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"columns\"] = non_empty_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825c85f-6cd0-4673-8c58-24c8c9f143b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Analytics_knowledge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86def8ba-9a01-437f-b996-a2c5d8e3d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/uav/Documents/AI_Hunter/LLMS/ulg_data/test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95d526-c591-469a-bc11-11d28e51c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6a3d7-dd12-4049-88f1-6b8561fddf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_empty_columns(df):\n",
    "    non_empty_columns = [col for col in df.columns if df[col].notnull().any()]\n",
    "    return non_empty_columns\n",
    "\n",
    "# Find non-empty columns in the DataFrame\n",
    "non_empty_columns = find_non_empty_columns(data)\n",
    "print(\"Non-empty columns:\", non_empty_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce3ff01-28d6-4822-b3db-d7b7433620d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(non_empty_columns),200):\n",
    "    print(\"=================================\")\n",
    "    print(i,non_empty_columns[i:i+250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f5fd4-5bde-451b-8457-c34160576d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agents\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240a30e-02ac-4dbc-b205-d58f3d217fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de576f3-a55d-446e-8780-fc56510088f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d2380-9342-4f6d-9607-655177101010",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Agents.Analytics_one(\"/home/uav/Documents/AI_Hunter/LLMS/LLM_simulation/i want to test in high temparature and  no wind involvement senarios_1.csv\")\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555e038-5bb0-4bec-a10e-9944329911e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Analytics_list = []\n",
    "pattern = 'Scenario (\\d+):\\n([\\s\\S]*?)\\n\\n'\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "for match in matches:\n",
    "    Analytics_list.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb773c4-0889-45d1-a81a-f8d955e74eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f9884-5cbc-4c6d-8f77-d39615ce61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for i in range(0,len(non_empty_columns),250):\n",
    "            #{Analytics_list[0][1]}\n",
    "    prompt_t= f\"\"\"\n",
    "    here are analytics i need for my root cause Analytics and\n",
    "    \"Analytics Topics\"  = {Analytics_list[0][1]}\n",
    "    ===============================\n",
    "    \"ulg_data columns\":-{non_empty_columns[i:i+250]}\n",
    "    and here are ulg data columns of my drone now tell me all what are columns required for above metrics\n",
    "    rules:\n",
    "    1)I have Given you \"Analytics Topics\" i need you to book contextually relevent \"ulg_data columns\" so that i can make better analytics of this data\n",
    "  \n",
    "    \"\"\"\n",
    "    print(prompt_t)\n",
    "    messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"I am an sUAS Software designer and I need your assistance on Automating UAV testing\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"I am an AI system capable of answering any query you have\"}, \n",
    "    {\"role\": \"user\", \"content\": prompt_t} ]\n",
    "\n",
    "    temp = 0.0\n",
    "    sample = False\n",
    "    tokens = 1000\n",
    "    agent_response = Agents.model_x(messages, temp, sample,tokens)\n",
    "    responses.append(agent_response[-1][\"content\"])\n",
    "    # 2) pick data columns that is 100% relavent to context given above\n",
    "    #  2) Make sure to use only columns above as if you makeup new names that will fail my pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d465cc2-3261-4aa1-8686-6b8760587575",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[2].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eafa4a-f10a-4721-b5d1-6959ce08986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_l = []\n",
    "for i in range(len(responses)):\n",
    "    pattern = r'-\\s*(\\S+)'\n",
    "    extracted_values = re.findall(pattern, responses[i])\n",
    "    columns_l.append(extracted_values)\n",
    "columns_l = [[item.strip(\"'\") for item in sublist] for sublist in columns_l]\n",
    "flattened_data = [item for sublist in columns_l for item in sublist]\n",
    "filtered_data = [item for item in flattened_data if item in non_empty_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb3fb4a-52ac-4372-9b2c-b6572e660192",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e522b-64ea-4d45-9c1b-39bb3d3cd02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analytics_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5f067-b3ce-454e-93c1-02828b565cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43d76e-0133-482a-8ad4-d90eaf2a0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d2b25-f15b-45c9-a7e3-d162c6de39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i\n",
    "def create_and_save_plots(data,filtered_data, output_folder):\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for column in filtered_data:\n",
    "        plt.figure()\n",
    "        plt.plot(data.index, data[column], label=column)\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel(column)\n",
    "        plt.title(f'Plot of {column}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plot_path = os.path.join(output_folder, f'{column}.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f'Saved plot for {column} at {plot_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9a477-05e1-4a25-952a-6fbff22a99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_save_plots(data,filtered_data,\"plots_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19613191-400f-4a28-85ba-adb86f459954",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [\"The image contains four separate line plots, each representing a different metric measured by a drone. The metrics are 'temperature_accel', 'signal_quality', 'v_xy_valid', and 'temperature_gyro'. Each plot has an 'Index' on the x-axis and a numerical value on the y-axis, which likely represents the percentage of agreement or a similar metric. The plots show fluctuations in the data points, with some peaks and troughs indicating variations in the measured values over the course of the drone's mission.\\n\\n\\n1. 'temperature_accel' plot: This plot shows a line graph with sharp peaks and valleys, suggesting that the drone's temperature acceleration readings vary significantly throughout its mission. The peaks could indicate moments of rapid acceleration, while the valleys may represent periods of slower movement or deceleration.\\n\\n2. 'signal_quality' plot: This plot has a relatively flat line close to the 100% mark, indicating that the signal quality remains consistently high throughout the mission. A slight dip to 96% suggests a minor drop in signal quality, which could be due to interference or signal loss.\\n\\n3. 'v_xy_valid' plot: This plot also shows a flat line, but at a lower percentage value of 100%. This suggests that the drone's positional accuracy in the x and y axes is always valid, with no instances of invalid data.\\n\\n4. 'temperature_gyro' plot: This plot has a similar pattern to the 'temperature_accel' plot, with sharp peaks and valleys, indicating that the drone's gyroscope readings vary. The peaks could represent moments of rapid change in orientation, while the valleys may indicate stable or unstable conditions.\\n\\n\\nAs a drone expert, I would advise closely monitoring these metrics to ensure the drone's performance and safety. The 'signal_quality' and 'v_xy_valid' plots are particularly important for maintaining communication and navigation accuracy. The 'temperature_accel' and 'temperature_gyro' plots are crucial for understanding the drone's movement dynamics and stability. Any significant deviations in these metrics could indicate potential issues that may affect the drone's operation\", \"The image contains three separate line plots, each representing a different metric related to drone preparedness for meetings. The metrics are 'power_input_valid', 'z_global', and 'xy_global', as well as 'xy_reset_counter'. Each plot has a horizontal axis labeled 'Index' and a vertical axis with a scale from 0 to 1.04, indicating the level of agreement or performance. The plots show a single line for each metric, suggesting a consistent level of agreement or performance across the data points.\\n\\n\\n1. 'power_input_valid' plot: This plot likely represents the percentage of respondents who agree that they have clear and pre-defined goals for meetings. The line is flat at the 1.00 mark, indicating a 100% agreement level. This suggests that all respondents are in full agreement with having clear and predefined goals for meetings.\\n\\n2. 'z_global' plot: This plot could be related to the understanding of the drone's exact role and responsibilities when invited to a meeting. The line is flat at the 1.00 mark, indicating a 100% agreement level. This suggests that all respondents are in full agreement with understanding their exact role and responsibilities.\\n\\n3. 'xy_global' plot: This plot might be about the understanding of the drone's exact role and responsibilities when invited to a meeting. The line is flat at the 1.00 mark, indicating a 100% agreement level. This suggests that all respondents are in full agreement with understanding their exact role and responsibilities.\\n\\n4. 'xy_reset_counter' plot: This plot could be related to the drone's ability to manage admin tasks like note-taking or summarization. The line is flat at the 1.00 mark, indicating a 100% agreement level. This suggests that all respondents are in full agreement with having more focus time to prepare for meetings.\\n\\n5. 'xy_valid' plot: This plot likely represents the percentage of respondents who agree that they have tools to manage admin tasks like note-taking or summarization. The line is flat at the 1.00 mark, indicating a 100% agreement level. This suggests\", \"The image contains three separate line plots, each representing a different metric measured by a drone. The first plot, labeled 'z_reset_counter', shows a horizontal line at the 0.00 mark, indicating no variance or change over the 16,000 index points. The second plot, 'v_z_valid', also displays a horizontal line at the 1.00 mark, suggesting a consistent value across the 16,000 index points. The third plot, 'temperature', has a horizontal line at the 13.48 mark, with minor fluctuations around this value across the 8,000 index points. The fourth plot, 'v_fov', shows a horizontal line at the 0.52 mark, with no variation over the 5,000 index points. The fifth plot, 'visual_odometry_timestamp_rel', has a horizontal line at the 33,500 mark, with slight variations around this value across the 5,000 index points.\\n\\nAs a drone expert, I would analyze these plots to understand the stability and consistency of the drone's performance metrics. The 'z_reset_counter' and 'v_z_valid' plots suggest that the drone's reset and validation processes are stable and unchanged over time. The 'temperature' plot indicates that the drone maintains a consistent temperature, which is crucial for optimal performance and avoiding overheating. The 'v_fov' plot indicates that the drone's field of view remains constant, ensuring consistent coverage during the mission. The 'visual_odometry_timestamp_rel' plot shows that the drone's visual odometry system maintains a stable relative timestamp, which is important for accurate navigation and tracking.\\n\\nThese metrics impact the drone's behavior by ensuring consistent performance and reliability. The stable metrics suggest that the drone is operating as expected, with no significant deviations that could affect its mission. However, the slight variations in the 'temperature' and 'visual_odometry_timestamp_rel' plots may require further investigation to determine if they are within acceptable limits or if they indicate potential issues that could impact the drone's performance.\\n\\nIn terms of drone behavior, the stable metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77354ce-6784-4c67-ada2-176019902659",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[2].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb0c5e8-7269-4de0-ad1b-4fccb63572cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = input(\"Enter your question or type 'exit' to finish: \")\n",
    "cosine_similarity, indices = search_a(user_query, 5)\n",
    "contextlist = Analytics_data.iloc[indices[0]][\"columns\"]\n",
    "context = combine_context(contextlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4201578-5057-4d57-85c6-39c151cb85f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
